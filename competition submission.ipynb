{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Models\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "\n",
    "# Model Evalutaion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_connectcome = pd.read_csv(\"TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv\")\n",
    "df_cat = pd.read_excel(\"TRAIN_CATEGORICAL_METADATA_new.xlsx\")\n",
    "df_quant = pd.read_excel(\"TRAIN_QUANTITATIVE_METADATA_new.xlsx\")\n",
    "df_solutions = pd.read_excel(\"TRAINING_SOLUTIONS.xlsx\")\n",
    "\n",
    "df_cat.drop(columns = ['Basic_Demos_Enroll_Year', 'PreInt_Demos_Fam_Child_Ethnicity'], inplace = True)\n",
    "\n",
    "tmp = pd.merge(df_cat, df_quant, on = 'participant_id')\n",
    "tmp1 = pd.merge(tmp, df_connectcome, on = 'participant_id')\n",
    "df = pd.merge(tmp1, df_solutions, on = 'participant_id')\n",
    "df.set_index('participant_id', inplace = True)\n",
    "y = df[['ADHD_Outcome', 'Sex_F']]\n",
    "x = df.drop(columns = ['ADHD_Outcome', 'Sex_F'])\n",
    "\n",
    "X_train, X_test, y_train, y_test, = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "cat_col = df_cat.drop(columns = ['participant_id']).columns\n",
    "quant_col = df_quant.drop(columns = 'participant_id').columns\n",
    "df_connectcome.set_index('participant_id', inplace = True)\n",
    "\n",
    "labels = ['ADHD', 'Sex']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_miss_cat_mode (df):\n",
    "    missing_percentage = df[cat_col].isna().mean() * 100\n",
    "    for column, miss in missing_percentage.items():\n",
    "        if miss < 5.0:\n",
    "        # since the missing values are less than 5% of the data, the are considered to be missinf completely at randaom and therefore imputed by the mean\n",
    "            mode_value = df[column].mode(dropna=True)[0]\n",
    "            df[column].fillna(mode_value, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of missing data is > 5%\n",
    "def custom_impute_cat(df):\n",
    "    # Impute occupation if it's missing but education is available\n",
    "    occ_by_edu = df.groupby('Barratt_Barratt_P2_Edu')['Barratt_Barratt_P2_Occ'].agg(lambda x: x.mode().iloc[0])\n",
    "    mask_occ_missing = df['Barratt_Barratt_P2_Occ'].isna() & df['Barratt_Barratt_P2_Edu'].notna()\n",
    "    df.loc[mask_occ_missing, 'Barratt_Barratt_P2_Occ'] = df.loc[mask_occ_missing, 'Barratt_Barratt_P2_Edu'].map(occ_by_edu)\n",
    "\n",
    "    # Impute education if it's missing but occupation is available\n",
    "    edu_by_occ = df.groupby('Barratt_Barratt_P2_Occ')['Barratt_Barratt_P2_Edu'].agg(lambda x: x.mode().iloc[0])\n",
    "    mask_edu_missing = df['Barratt_Barratt_P2_Edu'].isna() & df['Barratt_Barratt_P2_Occ'].notna()\n",
    "    df.loc[mask_edu_missing, 'Barratt_Barratt_P2_Edu'] = df.loc[mask_edu_missing, 'Barratt_Barratt_P2_Occ'].map(edu_by_occ)\n",
    "\n",
    "    # If both are missing, fill with default values\n",
    "    missing_both = df['Barratt_Barratt_P2_Edu'].isna() & df['Barratt_Barratt_P2_Occ'].isna()\n",
    "    df.loc[missing_both, 'Barratt_Barratt_P2_Edu'] = 0\n",
    "    df.loc[missing_both, 'Barratt_Barratt_P2_Occ'] = -1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_miss_quant (df):\n",
    "    missing_percentage = df[quant_col].isna().mean() * 100\n",
    "    for column, miss in missing_percentage.items():\n",
    "    # since the missing values are less than 5% of the data, the are considered to be missinf completely at randaom and therefore imputed by the mean\n",
    "        if miss < 5.0:\n",
    "            median_value = df[column].median(skipna=True)\n",
    "            df[column] = df[column].fillna(median_value)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of missing data is > 5%\n",
    "def custom_impute_quant (df):\n",
    "\n",
    "    missing_indices = df[df['MRI_Track_Age_at_Scan'].isna()].index\n",
    "    shuffled_indices = np.random.permutation(missing_indices)\n",
    "    \n",
    "    half = len(shuffled_indices) // 2\n",
    "    first_half = shuffled_indices[:half]\n",
    "    second_half = shuffled_indices[half:]\n",
    "    \n",
    "    df.loc[first_half, 'MRI_Track_Age_at_Scan'] = 9\n",
    "    df.loc[second_half, 'MRI_Track_Age_at_Scan'] = 10\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handling_missing (df):\n",
    "    df = impute_miss_cat_mode(df)\n",
    "    df = custom_impute_cat(df)\n",
    "    df = impute_miss_quant(df)\n",
    "    df = custom_impute_quant(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale quantitavie data only\n",
    "def st_scale (df):\n",
    "    scaler = StandardScaler()\n",
    "    scaled_values = scaler.fit_transform(df[quant_col])\n",
    "    tmp = pd.DataFrame(scaled_values, columns=quant_col, index=df.index)\n",
    "    return pd.concat([df.drop(columns=quant_col), tmp] , axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the output labels to one target label and balance the \"not majority\" class which all the classes that are males with ADHD = 10\n",
    "def smote (x,y):\n",
    "\n",
    "    y_combined = y['ADHD_Outcome'].astype(str) + \"_\" + y['Sex_F'].astype(str)\n",
    "    smote = SMOTE(sampling_strategy='not majority', k_neighbors=5)\n",
    "    X_res, y_combined_res = smote.fit_resample(x, y_combined)\n",
    "    # after balancing the labels split back the target output into two columns\n",
    "    y_split = y_combined_res.str.split(\"_\", expand=True)\n",
    "    y_res = pd.DataFrame({\n",
    "        'ADHD_Outcome': y_split[0].astype(int),\n",
    "        'Sex_F': y_split[1].astype(int) })\n",
    "\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE_HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for all categoricak features\n",
    "def one_hot_encoding(df):\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    df_enc = encoder.fit_transform(df[cat_col])\n",
    "    encoded_cols = encoder.get_feature_names_out(cat_col)\n",
    "    df_encoded = pd.DataFrame(df_enc, columns=encoded_cols, index=df.index)\n",
    "    df_final = pd.concat([df.drop(columns=cat_col), df_encoded], axis=1)\n",
    "    return df_final , encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8624\\3167548674.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(mode_value, inplace=True)\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8624\\3167548674.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[column].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_train = handling_missing(X_train)\n",
    "X_train, enc = one_hot_encoding(X_train)\n",
    "X_train = st_scale(X_train)\n",
    "X_train,y_train = smote(X_train,y_train)\n",
    "\n",
    "X_test = handling_missing(X_test)\n",
    "t = pd.DataFrame(\n",
    "    enc.transform(X_test[cat_col]),\n",
    "    columns=enc.get_feature_names_out(cat_col),\n",
    "    index=X_test.index\n",
    ")\n",
    "X_test= pd.concat([X_test.drop(columns=cat_col), t], axis = 1)\n",
    "X_test = st_scale(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custome Multioutput Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 541 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ADHD Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.77      0.63        97\n",
      "           1       0.90      0.76      0.82       267\n",
      "\n",
      "    accuracy                           0.76       364\n",
      "   macro avg       0.72      0.76      0.73       364\n",
      "weighted avg       0.80      0.76      0.77       364\n",
      "\n",
      "[[ 75  22]\n",
      " [ 65 202]]\n",
      "=== Gender Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82       233\n",
      "           1       0.72      0.46      0.56       131\n",
      "\n",
      "    accuracy                           0.74       364\n",
      "   macro avg       0.74      0.68      0.69       364\n",
      "weighted avg       0.74      0.74      0.72       364\n",
      "\n",
      "[[210  23]\n",
      " [ 71  60]]\n"
     ]
    }
   ],
   "source": [
    "class CustomMultiOutputClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimators):\n",
    "        \"\"\"\n",
    "        estimators: list of (name, estimator) tuples\n",
    "        Each estimator will predict one column of the target.\n",
    "        \"\"\"\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Fit each estimator to its respective output label (column of Y).\n",
    "        \"\"\"\n",
    "        self.fitted_estimators_ = []\n",
    "        for i, (name, estimator) in enumerate(self.estimators):\n",
    "            est = clone(estimator)\n",
    "            est.fit(X, Y.iloc[:, i])\n",
    "            self.fitted_estimators_.append((name, est))\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict each output label using its respective estimator.\n",
    "        Returns a 2D numpy array: [n_samples, n_outputs]\n",
    "        \"\"\"\n",
    "        preds = []\n",
    "        for name, est in self.fitted_estimators_:\n",
    "            pred = est.predict(X)\n",
    "            preds.append(pred.reshape(-1, 1))  \n",
    "        return np.hstack(preds)\n",
    "\n",
    "lr_model = LogisticRegression(class_weight={0: 4, 1: 1 } , verbose=1, solver='saga', max_iter=700,penalty='l1') # solver='saga', max_iter=1000,penalty='l1'\n",
    "xgb = xgb.XGBClassifier(scale_pos_weight= 0.25)\n",
    "\n",
    "custom_model = CustomMultiOutputClassifier([\n",
    "    ('ADHD_Outcome', xgb),    \n",
    "    ('Sex_F', lr_model) \n",
    "])\n",
    "\n",
    "custom_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = custom_model.predict(X_test)\n",
    "\n",
    "print(\"=== ADHD Classification Report ===\")\n",
    "print(classification_report(y_test['ADHD_Outcome'], y_pred[:, 0]))\n",
    "print(confusion_matrix(y_test['ADHD_Outcome'], y_pred[:, 0]))\n",
    "\n",
    "print(\"=== Gender Classification Report ===\")\n",
    "print(classification_report(y_test['Sex_F'], y_pred[:, 1]))\n",
    "print(confusion_matrix(y_test['Sex_F'], y_pred[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
